{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abharathkumarr/Projects-on-RAG/blob/main/rag_pipeline_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a96be8b-e178-4790-acdf-3d618db79275",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "2a96be8b-e178-4790-acdf-3d618db79275"
      },
      "source": [
        "# README: Retrieval-Augmented Generation (RAG) Pipeline for Carroll_SG.pdf\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook implements a Retrieval-Augmented Generation (RAG) pipeline to extract text from a PDF, build semantic embeddings, retrieve relevant information based on a query, and generate responses using a GPT-based model. The primary steps are:\n",
        "\n",
        "1. **Text Extraction:**  \n",
        "   - **Tool:** PyPDF2  \n",
        "   - **Challenge:** Some pages in the original PDF did not yield any text due to non-standard internal formatting.  \n",
        "   - **Resolution:** The PDF was re-saved from a browser to \"flatten\" its internal structure, resulting in successful text extraction for some pages.\n",
        "\n",
        "2. **Text Preprocessing and Chunking:**  \n",
        "   - The extracted text is split into overlapping chunks. This ensures that context is preserved across chunk boundaries, which is critical for accurate retrieval later.\n",
        "\n",
        "3. **Embedding Generation & Indexing:**  \n",
        "   - **Tool:** Sentence Transformers (`all-mpnet-base-v2`)  \n",
        "   - Each text chunk is encoded into a dense vector, and a FAISS index is built for efficient similarity search.\n",
        "\n",
        "4. **Query Retrieval:**  \n",
        "   - A user query is encoded and used to search the FAISS index to find the most similar text chunks.\n",
        "\n",
        "5. **Response Generation:**  \n",
        "   - **Tool:** GPT-2 via Hugging Face’s Transformers pipeline  \n",
        "   - The retrieved context is combined with the query to form a prompt, and a GPT-based model generates a response.\n",
        "\n",
        "## Challenges and Solutions\n",
        "\n",
        "- **Text Extraction Variability:**  \n",
        "  Some pages in the original PDF did not yield extractable text due to how the text was stored internally. After re-saving the PDF from the browser, some pages still had zero-length text, indicating they might be scanned images or use a non-standard layout. In such cases, fallback methods like OCR or alternative libraries (e.g., pdfplumber, PyMuPDF) were considered.\n",
        "\n",
        "- **Parameter Tuning:**  \n",
        "  Decisions were made regarding the chunk size (e.g., 500 words with a 50-word overlap) to ensure sufficient context without overwhelming the embedding model.  \n",
        "  The number of retrieved chunks (`k`) was also tuned to balance between context and response clarity.\n",
        "\n",
        "- **Generation Configuration:**  \n",
        "  Adjustments were needed in the generation pipeline to handle truncation and avoid conflicts with unwanted configuration keys (such as a progress bar setting) in GPT-2's generation method.\n",
        "\n",
        "## Key Decisions\n",
        "\n",
        "- **Model Selection:**  \n",
        "  - **Sentence Transformer:** `all-mpnet-base-v2` was chosen for its strong performance on semantic similarity tasks.\n",
        "  - **Generative Model:** GPT-2 was used as a baseline generative model, which can be replaced or fine-tuned for more specific domains if needed.\n",
        "\n",
        "- **Indexing with FAISS:**  \n",
        "  FAISS was used for its speed and efficiency in handling high-dimensional vector searches, which is critical when working with multiple text chunks.\n",
        "\n",
        "- **Pipeline Modularity:**  \n",
        "  The process is modular, allowing easy substitution of different components (e.g., text extraction libraries, embedding models, or generative models) to suit future needs.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "This notebook demonstrates a complete end-to-end RAG pipeline. It not only retrieves and generates responses based on a PDF’s content but also documents the approach, challenges, and design decisions. Future improvements could involve fine-tuning the generative model or integrating a user-friendly interface (e.g., using Streamlit or Gradio)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "defb4e32-297c-459d-a6e0-0a5456483345",
      "metadata": {
        "id": "defb4e32-297c-459d-a6e0-0a5456483345"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c6a38d3-d0b3-4f3f-bb05-56ba6e2c7cd7",
      "metadata": {
        "id": "7c6a38d3-d0b3-4f3f-bb05-56ba6e2c7cd7"
      },
      "source": [
        "# 2. Extract Text from PDF using PyPDF2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d770a27-0bd8-4354-8143-7acb1b3afaaf",
      "metadata": {
        "id": "6d770a27-0bd8-4354-8143-7acb1b3afaaf",
        "outputId": "a2f7ef51-560d-4c62-edd4-b901ad7e5f35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preview of extracted text:\n",
            "\n",
            "--- Page 1 ---\n",
            "An Introduction  to General Relativity\n",
            "E SPACETIM\n",
            "and\n",
            "GEOMETRY\n",
            "Sean M. Carroll\n",
            "--- Page 2 ---\n",
            "SPACETIME  AND  GEOMETRY\n",
            "An  Introduction  to General  Relativity\n",
            "Sean  Carroll\n",
            "University  of Chicago\n",
            "Addison\n",
            "Wesley\n",
            "CapetownSan Francisco Boston New York\n",
            "Mexico  City\n",
            "Sydney Tokyo TorontoHong Kong London Madrid\n",
            "Montreal Munich Paris Singapore\n",
            "--- Page 3 ---\n",
            "Acquisitions  Editor:  Adam Black\n",
            "Project  Editor: Nancy  Benton\n",
            "Text Designer:  Leslie  Galen\n",
            "Cover  Designer:  Blakeley  Kim\n",
            "Mar\n"
          ]
        }
      ],
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts text from each page of the PDF.\"\"\"\n",
        "    text = \"\"\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        for i, page in enumerate(pdf_reader.pages):\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += f\"\\n--- Page {i+1} ---\\n\" + page_text\n",
        "    return text\n",
        "\n",
        "pdf_path = \"/Users/abharathkumar/Downloads/Carroll_SG.pdf\"\n",
        "document_text = extract_text_from_pdf(pdf_path)\n",
        "print(\"Preview of extracted text:\")\n",
        "print(document_text[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f641fa0-dec8-49cb-bdb9-cd04d91a5d90",
      "metadata": {
        "id": "8f641fa0-dec8-49cb-bdb9-cd04d91a5d90"
      },
      "source": [
        "# 3. Preprocess & Chunk the Text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31a1a966-e7f2-4516-9931-2d1c5cbaa409",
      "metadata": {
        "id": "31a1a966-e7f2-4516-9931-2d1c5cbaa409",
        "outputId": "0815acad-667a-4766-cb0f-5b2b09bf0aa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total chunks created: 3\n",
            "Preview of first chunk:\n",
            "--- Page 1 --- An Introduction to General Relativity E SPACETIM and GEOMETRY Sean M. Carroll --- Page 2 --- SPACETIME AND GEOMETRY An Introduction to General Relativity Sean Carroll University of Chicago Addison Wesley CapetownSan Francisco Boston New York Mexico City Sydney Tokyo TorontoHong Kong London Madrid Montreal Munich Paris Singapore --- Page 3 --- Acquisitions Editor: Adam Black Project Editor: Nancy Benton Text Designer: Leslie Galen Cover Designer: Blakeley Kim Marketing Manager: Chr\n"
          ]
        }
      ],
      "source": [
        "def chunk_text(text, chunk_size=500, overlap=50):\n",
        "    \"\"\"\n",
        "    Splits text into chunks of 'chunk_size' words with an 'overlap' between chunks.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(words):\n",
        "        end = min(start + chunk_size, len(words))\n",
        "        chunk = \" \".join(words[start:end])\n",
        "        chunks.append(chunk)\n",
        "        start += (chunk_size - overlap)\n",
        "    return chunks\n",
        "\n",
        "chunks = chunk_text(document_text, chunk_size=500, overlap=50)\n",
        "print(\"Total chunks created:\", len(chunks))\n",
        "print(\"Preview of first chunk:\")\n",
        "print(chunks[0][:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57d7b358-70db-405a-bb44-8def6718ac08",
      "metadata": {
        "id": "57d7b358-70db-405a-bb44-8def6718ac08"
      },
      "source": [
        "# 4. Generate Embeddings & Build FAISS Index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf8fc0b7-764e-476b-b518-ee1f366ef2bd",
      "metadata": {
        "id": "bf8fc0b7-764e-476b-b518-ee1f366ef2bd",
        "outputId": "9ab2d2eb-d766-427f-a068-dd6ffaef6b8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating embeddings for chunks...\n",
            "FAISS index built with 3 vectors.\n"
          ]
        }
      ],
      "source": [
        "embedder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
        "\n",
        "print(\"Generating embeddings for chunks...\")\n",
        "chunk_embeddings = embedder.encode(chunks, show_progress_bar=False)\n",
        "\n",
        "# Convert embeddings to a NumPy array and build a FAISS index\n",
        "embedding_dim = chunk_embeddings.shape[1]\n",
        "embeddings_np = np.array(chunk_embeddings)\n",
        "index = faiss.IndexFlatL2(embedding_dim)\n",
        "index.add(embeddings_np)\n",
        "print(\"FAISS index built with\", index.ntotal, \"vectors.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5f65a2d-1f3c-4451-bae6-77ae0447e71a",
      "metadata": {
        "id": "c5f65a2d-1f3c-4451-bae6-77ae0447e71a"
      },
      "source": [
        "# 5. Retrieve Relevant Chunks for a Query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb379095-a3c4-4050-8150-11832f65b8f9",
      "metadata": {
        "id": "eb379095-a3c4-4050-8150-11832f65b8f9",
        "outputId": "007c113d-593f-45c6-bcf6-317d4295bb5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved Chunks:\n",
            "\n",
            "--- Chunk 1 ---\n",
            "In ad- dition to being an active research area in its own right, GR is part of the standard syllabus for anyone interested in astrophysics, cosmology, string theory, and even particle physics. This is not to slight the more pragmatic uses of GR, including the workings of the Global Positioning Syste\n",
            "\n",
            "--- Chunk 2 ---\n",
            "detailed formalism, but have also attempted to include concrete examples and informal discussion of the concepts under consideration. Much of the most mathematical material has been relegated to the Appendices. Some of the material in the Appendices is actually an integral part of the course (for ex\n"
          ]
        }
      ],
      "source": [
        "def retrieve_relevant_chunks(query, embedder, index, chunks, k=2):\n",
        "    \"\"\"\n",
        "    Encodes the query, searches the FAISS index, and returns the top 'k' matching chunks.\n",
        "    \"\"\"\n",
        "    query_embedding = embedder.encode([query])\n",
        "    distances, indices = index.search(np.array(query_embedding), k)\n",
        "    retrieved_chunks = [chunks[i] for i in indices[0]]\n",
        "    return retrieved_chunks\n",
        "\n",
        "# Define your query\n",
        "query = \"What is the main idea behind General Relativity?\"\n",
        "\n",
        "# Retrieve the most relevant chunks\n",
        "relevant_chunks = retrieve_relevant_chunks(query, embedder, index, chunks, k=2)\n",
        "print(\"Retrieved Chunks:\")\n",
        "for idx, chunk in enumerate(relevant_chunks, 1):\n",
        "    print(f\"\\n--- Chunk {idx} ---\")\n",
        "    print(chunk[:300])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9c84b66-31b9-407a-a0a8-331efc3dadc0",
      "metadata": {
        "id": "a9c84b66-31b9-407a-a0a8-331efc3dadc0"
      },
      "source": [
        "# 6. Generate a Response Using a GPT-based Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d81bf2f-6384-4ec3-890a-69ebd4803a21",
      "metadata": {
        "id": "9d81bf2f-6384-4ec3-890a-69ebd4803a21",
        "outputId": "62533a8f-8a5c-4d8f-e3c2-b35c0306a16d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use mps:0\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (1024). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Response:\n",
            "\n",
            "Context: In ad- dition to being an active research area in its own right, GR is part of the standard syllabus for anyone interested in astrophysics, cosmology, string theory, and even particle physics. This is not to slight the more pragmatic uses of GR, including the workings of the Global Positioning System (GPS) satellite network. There is no shortage of books on GR, and many of them are excellent. Indeed, approximately thirty years ago witnessed the appearance of no fewer than three books in the subject, each of which has become a classic in its own right: those by Weinberg (1972), Misner, Thorne, and Wheeler (1973), and Hawking and Ellis (1975). Each of these books is suffused with a strongly-held point of view advo- cated by the authors. This has led to a love-hate relationship between these works and their readers; in each case, it takes little effort to find students who will de- clare them to be the best textbook ever written, or other students who find them completely unpalatable. For the individuals in question, these judgments may very well be correct; there are many different ways to approach this subject. The present book has a single purpose: to provide a clear introduction to gen- eral relativity, suitable for graduate students or advanced undergraduates. I have attempted to include enough material so that almost any one-semester introduc- tory course on GR can find the appropriate subjects covered in the text, but not too much more than that. In particular, I have tried to resist the temptation to write a comprehensive reference book. The only goal of this book is to teach you GR. An intentional effort has been made to prefer the conventional over the id- iosyncratic. If I can be accused of any particular ideological bias, it would be a vii --- Page 7 --- viii Preface tendency to think of general relativity as a field theory, a point of view that helps one to appreciate the connections among GR, particle physics, and string theory. At the same time, there are a number of exciting astrophysical applications of GR (black holes, gravitational lensing, the production and detection of gravitational waves, the early universe, the late universe, the cosmological constant), and I have endeavored to include at least enough background discussion of these issues to prepare students to tackle the current literature. The primary question facing any introductory treatment of general relativity is the level of mathematical rigor at which to operate. There is no uniquely proper solution, as different students will respond with different levels of understanding and enthusiasm to different approaches. Recognizing this, I have tried to pro- vide something for everyone. I have not shied away from detailed formalism, but have also attempted to include concrete examples and informal discussion of the concepts under consideration. Much of the most mathematical material has been relegated to the Appendices. Some of the material in the Appendices is actually an integral part of the course (for example, the discussion of\n",
            "detailed formalism, but have also attempted to include concrete examples and informal discussion of the concepts under consideration. Much of the most mathematical material has been relegated to the Appendices. Some of the material in the Appendices is actually an integral part of the course (for example, the discussion of conformal diagrams), but an individual reader or instructor can decide just when it is appropriate to delve into them; signposts are included in the body of the text. Surprisingly, there are very few formal prerequisites for learning general rel- ativity; most of the material is developed as we go along. Certainly no prior ex- posure to Riemannian geometry is assumed, nor would it necessarily be helpful. It would be nice to have already studied some special relativity; although a dis- cussion is included in Chapter 1, its purpose is more to review the basics and and introduce some notation, rather than to provide a self-contained introduction. Be- yond that, some exposure to electromagnetism, Lagrangian mechanics, and linear algebra might be useful, but the essentials are included here. The structure of the book should be clear. The first chapter is a review of spe- cial relativity and basic tensor algebra, including a brief discussion of classical field theory. The next two chapters introduce manifolds and curvature in some detail; some motivational physics is included, but building a mathematical frame- work is the primary goal. General relativity proper is introduced in Chapter 4, along with some discussion of alternative theories. The next four chapters dis- cuss the three major applications of GR: black holes (two chapters), perturbation theory and gravitational waves, and cosmology. Each of these subjects has wit- nessed an explosion of research in recent years, so the discussions here will be necessarily introductory, but I have tried to emphasize issues of relevance to cur- rent work. These three applications can be covered in any order, although there are interdependencies highlighted in the text. Discussions of experimental tests are sprinkled through these chapters. Chapter 9 is a brief introduction to quan- tum field theory in curved spacetime; this is not a necessary part of a first look at GR, but has become increasingly important to work in quantum gravity and cosmology, and therefore deserves some mention. On the other hand, a few topics are scandalously neglected; the initial-value problem and cosmological perturba- tion theory come to mind, but there are others. Fortunately there is no shortage of other resources. The Appendices serve various purposes: There are discussions of\n",
            "\n",
            "Query: What is the main idea behind General Relativity?\n",
            "Answer: list of subjects. An Introduction: General Relative Relativity. Particles A. Introduction, General Reli- tectic Relices, and General Relics and Relices. In General Relix. In General Relix. A. Rel\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the text generation pipeline with GPT-2 and disable the progress bar.\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\", progress_bar=False)\n",
        "\n",
        "# Directly set the progress_bar attribute in the generation_config to None.\n",
        "try:\n",
        "    generator.generation_config.progress_bar = None\n",
        "except Exception as e:\n",
        "    print(\"Could not set progress_bar to None:\", e)\n",
        "\n",
        "# Combine the retrieved chunks as context (assuming relevant_chunks and query are defined)\n",
        "context = \"\\n\".join(relevant_chunks)\n",
        "prompt = f\"Context: {context}\\n\\nQuery: {query}\\nAnswer:\"\n",
        "\n",
        "# Generate a response with truncation enabled.\n",
        "generated_response = generator(prompt, max_new_tokens=50, do_sample=True, truncation=True)[0]['generated_text']\n",
        "print(\"Generated Response:\\n\")\n",
        "print(generated_response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73dd6022-30ee-4f64-8859-818d164c8537",
      "metadata": {
        "id": "73dd6022-30ee-4f64-8859-818d164c8537"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
